{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TFServing_Week1_Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XXdEnmVvXdUa"
      },
      "source": [
        "# Train Your Own Model and Serve It With TensorFlow Serving\n",
        "\n",
        "In this notebook, you will train a neural network to classify images of handwritten digits from the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. You will then save the trained model, and serve it using [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cSfb9Qd5XdFL"
      },
      "source": [
        "**Warning: This notebook is designed to be run in a Google Colab only**.  It installs packages on the system and requires root access. If you want to run it in a local Jupyter notebook, please proceed with caution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jcLTAmF5Xs2T"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%204%20-%20TensorFlow%20Serving/Week%201/Exercises/TFServing_Week1_Exercise.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%204%20-%20TensorFlow%20Serving/Week%201/Exercises/TFServing_Week1_Exercise.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i2Q8bkjeYTl-"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g8r89tTPI-Kb",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XGFJmWjrKttn",
        "outputId": "726ad306-d2d5-4a2b-f091-f15edb68516e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "â€¢ Using TensorFlow Version: 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pq-214o8SNt0"
      },
      "source": [
        "## Import the MNIST Dataset\n",
        "\n",
        "The [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains 70,000 grayscale images of the digits 0 through 9. The images show individual digits at a low resolution (28 by 28 pixels). \n",
        "\n",
        "Even though these are really images, we will load them as NumPy arrays and not as binary image objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MqDQO0KCaWS",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AIT-qX0QzLo-",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Scale the values of the arrays below to be between 0.0 and 1.0.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mIDGu-EEzdKb"
      },
      "source": [
        "In the cell below use the `.reshape` method to resize the arrays to the following sizes:\n",
        "\n",
        "```python\n",
        "train_images.shape: (60000, 28, 28, 1)\n",
        "test_images.shape: (10000, 28, 28, 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XsIxeG6BzN4t",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Reshape the arrays below.\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aUw8ZxigB1Nx",
        "outputId": "7cca191f-e384-4833-c081-5d45365878c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('\\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
        "print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train_images.shape: (60000, 28, 28, 1), of float64\n",
            "test_images.shape: (10000, 28, 28, 1), of float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DcR0OKbOSj0c"
      },
      "source": [
        "## Look at a Sample Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VQMs4v_oSo9v",
        "outputId": "4dc94a4d-bbf5-499d-c982-bac878268311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "idx = 42\n",
        "\n",
        "plt.imshow(test_images[idx].reshape(28,28), cmap=plt.cm.binary)\n",
        "plt.title('True Label: {}'.format(test_labels[idx]), fontdict={'size': 16})\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rn_-9OsPYnDp"
      },
      "source": [
        "## Build a Model\n",
        "\n",
        "In the cell below build a `tf.keras.Sequential` model that can be used to classify the images of the MNIST dataset. Feel free to use the simplest possible CNN. Make sure your model has the correct `input_shape` and the correct number of output units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EgMgJJynMbVY",
        "outputId": "e4a88a67-747b-4071-a214-3d7b7fabbd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# EXERCISE: Create a model.\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3,\n",
        "                               strides=2, activation='relu', name='Conv1'),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv1 (Conv2D)               (None, 13, 13, 8)         80        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1352)              0         \n",
            "_________________________________________________________________\n",
            "Softmax (Dense)              (None, 10)                13530     \n",
            "=================================================================\n",
            "Total params: 13,610\n",
            "Trainable params: 13,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bLzXnZT1YvS6"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "In the cell below configure your model for training using the `adam` optimizer, `sparse_categorical_crossentropy` as the loss, and `accuracy` for your metrics. Then train the model for the given number of epochs, using the `train_images` array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LTNN0ANGgA36",
        "outputId": "97f4a15f-f77c-4fc8-b21e-fb4b94d7b222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# EXERCISE: Configure the model for training.\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "# EXERCISE: Train the model.\n",
        "history = model.fit(train_images, train_labels, epochs=epochs)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3696 - accuracy: 0.8978\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2051 - accuracy: 0.9410\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1580 - accuracy: 0.9538\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1289 - accuracy: 0.9625\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1071 - accuracy: 0.9681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Er_vrDhf4qu5"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gMD387B93f2g",
        "outputId": "8404a4a7-a62d-4141-dc72-bc3f10774bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# EXERCISE: Evaluate the model on the test images.\n",
        "results_eval = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "for metric, value in zip(model.metrics_names, results_eval):\n",
        "    print(metric + ': {:.3}'.format(value))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.111\n",
            "accuracy: 0.966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WGfmT8M1Yx5y"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9uFDoDW_7HX6",
        "outputId": "c1333059-693a-4032-f1ec-89d9d62720d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "MODEL_DIR = tempfile.gettempdir()\n",
        "\n",
        "version = 1\n",
        "\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "if os.path.isdir(export_path):\n",
        "    print('\\nAlready saved a model, cleaning up\\n')\n",
        "    !rm -r {export_path}\n",
        "\n",
        "model.save(export_path, save_format=\"tf\")\n",
        "\n",
        "print('\\nexport_path = {}'.format(export_path))\n",
        "!ls -l {export_path}"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Already saved a model, cleaning up\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n",
            "\n",
            "export_path = /tmp/1\n",
            "total 84\n",
            "drwxr-xr-x 2 root root  4096 May 23 09:46 assets\n",
            "-rw-r--r-- 1 root root 76073 May 23 09:46 saved_model.pb\n",
            "drwxr-xr-x 2 root root  4096 May 23 09:46 variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KziE3e9tY-hH"
      },
      "source": [
        "## Examine Your Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LU4GDF_aYtfQ",
        "outputId": "f7d45ee7-adec-45b7-b3ab-89838da625fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['Conv1_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_Conv1_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['Softmax'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0523 09:46:56.187202 139716287264640 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AsDTdBGHZAzo"
      },
      "source": [
        "## Add TensorFlow Serving Distribution URI as a Package Source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EWg9X2QHlbGS",
        "outputId": "650c9ba5-b6cb-40f2-f57c-6535aa772623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
        "# You would instead do:\n",
        "# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0   114k      0 --:--:-- --:--:-- --:--:--  114k\n",
            "OK\n",
            "Hit:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "52 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4l5XkzqNZNBU"
      },
      "source": [
        "## Install TensorFlow Serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ygwa9AgRloYy",
        "outputId": "e9e60ab2-646c-4415-8e5d-cca97dac2366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 63%\r\rReading package lists... 63%\r\rReading package lists... 63%\r\rReading package lists... 63%\r\rReading package lists... 71%\r\rReading package lists... 71%\r\rReading package lists... 71%\r\rReading package lists... 71%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "tensorflow-model-server is already the newest version (2.1.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qd_PobAKZWW8"
      },
      "source": [
        "## Run the TensorFlow Model Server\n",
        "\n",
        "You will now launch the TensorFlow model server with a bash script. In the cell below use the following parameters when running the TensorFlow model server:\n",
        "\n",
        "* `rest_api_port`: Use port `8501` for your requests.\n",
        "\n",
        "\n",
        "* `model_name`: Use `digits_model` as your model name. \n",
        "\n",
        "\n",
        "* `model_base_path`: Use the environment variable `MODEL_DIR` defined below as the base path to the saved model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aUgp3vUdU5GS",
        "colab": {}
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kJDhHNJVnaLN",
        "outputId": "4085645a-f70f-4468-972f-807d6785e41d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# EXERCISE: Fill in the missing code below.\n",
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port= 8501 \\\n",
        "  --model_name= digits_model \\\n",
        "  --model_base_path= \"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IxbeiOCUUs2z",
        "outputId": "ec71c3f1-999c-46be-cd06-122c81f1befb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t--ssl_config_file=\"\"             \tstring\tIf non-empty, read an ascii SSLConfig protobuf from the supplied file name and set up a secure gRPC channel\n",
            "\t--platform_config_file=\"\"        \tstring\tIf non-empty, read an ascii PlatformConfigMap protobuf from the supplied file name, and use that platform config instead of the Tensorflow platform. (If used, --enable_batching is ignored.)\n",
            "\t--per_process_gpu_memory_fraction=0.000000\tfloat\tFraction that each process occupies of the GPU memory space the value is between 0.0 and 1.0 (with 0.0 as the default) If 1.0, the server will allocate all the memory when the server starts, If 0.0, Tensorflow will automatically select a value.\n",
            "\t--saved_model_tags=\"serve\"       \tstring\tComma-separated set of tags corresponding to the meta graph def to load from SavedModel.\n",
            "\t--grpc_channel_arguments=\"\"      \tstring\tA comma separated list of arguments to be passed to the grpc server. (e.g. grpc.max_connection_age_ms=2000)\n",
            "\t--enable_model_warmup=true       \tbool\tEnables model warmup, which triggers lazy initializations (such as TF optimizations) at load time, to reduce first request latency.\n",
            "\t--version=false                  \tbool\tDisplay version\n",
            "\t--monitoring_config_file=\"\"      \tstring\tIf non-empty, read an ascii MonitoringConfig protobuf from the supplied file name\n",
            "\t--remove_unused_fields_from_bundle_metagraph=true\tbool\tRemoves unused fields from MetaGraphDef proto message to save memory.\n",
            "\t--use_tflite_model=false         \tbool\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Load and use TensorFlow Lite model from `model.tflite` file in SavedModel directory instead of the TensorFlow model from `saved_model.pb` file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6mUrIWVRZdNu"
      },
      "source": [
        "## Create JSON Object with Test Images\n",
        "\n",
        "In the cell below construct a JSON object and use the first three images of the testing set (`test_images`) as your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2dsD7KQG1m-R",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Create JSON Object\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_images[0:3].tolist()})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TRdyPl4CZ5CU"
      },
      "source": [
        "## Make Inference Request\n",
        "\n",
        "In the cell below, send a predict request as a POST to the server's REST endpoint, and pass it your test data. You should ask the server to give you the latest version of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vGvFyuIzW6n6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "08a87b49-dc5b-45a9-c835-4510e19a8b05"
      },
      "source": [
        "# EXERCISE: Fill in the code below\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/digits_model:predict', data=data, headers=headers)\n",
        "\n",
        "predictions = json.loads(json_response.text)['predictions']"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 159\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 168\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f4e8e2b7ba8>: Failed to establish a new connection: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=8501): Max retries exceeded with url: /v1/models/digits_model:predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4e8e2b7ba8>: Failed to establish a new connection: [Errno 111] Connection refused',))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-bf0662019517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# EXERCISE: Fill in the code below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"content-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://localhost:8501/v1/models/digits_model:predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=8501): Max retries exceeded with url: /v1/models/digits_model:predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4e8e2b7ba8>: Failed to establish a new connection: [Errno 111] Connection refused',))"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FtrFMts_ackX"
      },
      "source": [
        "## Plot Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BxQzj34aiDz1",
        "outputId": "ba123319-04f6-4dd5-8b92-fa432c73e19e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "plt.figure(figsize=(10,15))\n",
        "\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(test_images[i].reshape(28,28), cmap = plt.cm.binary)\n",
        "    plt.axis('off')\n",
        "    color = 'green' if np.argmax(predictions[i]) == test_labels[i] else 'red'\n",
        "    plt.title('Prediction: {}\\nTrue Label: {}'.format(np.argmax(predictions[i]), test_labels[i]), color=color)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-475b14ba042d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'green'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction: {}\\nTrue Label: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALIAAACyCAYAAADmipVoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAEqElEQVR4nO3dsSvtfxzH8Xt+XblF0skgRcmpI6UMBgwMpIhBMvkPDEa7mZFB/AksEhYhZ1CULAYTFqUwGJTo/Ja7eX8vTg7nPD0f48uJ7/DsWz6+zknl8/lfUrn777svQPoMhiwEQxaCIQvBkIVgyEL4/cbXPZtTqUlFo3dkIRiyEAxZCIYsBEMWgiELwZCFYMhCMGQhGLIQDFkIhiwEQxaCIQvBkIVgyEIwZCEYshAMWQiGLARDFoIhC8GQhWDIQjBkIRiyEAxZCIYsBEMWgiELwZCFYMhCMGQhGLIQDFkIhiwEQxaCIQvBkIXw1ufslYzV1dVwX15eDveGhoZw//PnT7hPTk6Ge319fbhnMplw1/fwjiwEQxaCIQvBkIVgyEJI5fP5f339n1/8Ss3NzeF+cXFR1J9bU1MT7m1tbUX9ucXU2NgY7jMzM+He2dlZzMv5qFQ0ekcWgiELwZCFYMhCMGQhlM2zFisrK+F+enoa7kmnCmdnZ+F+cnIS7nt7e+F+eHgY7k1NTa+2q6ur8LUfVVFREe51dXXhfn19He5J1550mlFipxYh78hCMGQhGLIQDFkIhiyEsnnW4rvc39+He9IpR/Qb/tHR0adcS2VlZbhns9lwb21tDfe7u7twX1xcDPepqal3XN2X8VkLcRmyEAxZCIYsBEMWgqcWAGtra+E+MTER7u3t7eG+u7sb7ul0urALKw5PLcRlyEIwZCEYshAMWQieWpSRm5ubcE86hUh6fdI7m46Pjxd2YV/LUwtxGbIQDFkIhiwEQxZC2byvhZL/gyPpdKK2tjbck/6jpJx5RxaCIQvBkIVgyELwT9QlKJfLhXt/f3+4Pz09hfv+/n649/b2FnZhpcE/UYvLkIVgyEIwZCEYshD8E3UJ2tzcDPek04mBgYFw7+7u/rRrKnXekYVgyEIwZCEYshAMWQieWnyjx8fHcN/e3g73pI9emJ2dDfekD5gk8o4sBEMWgiELwZCFYMhC8NTiG83NzYV70odRDg0NhXtPT8+nXVO58o4sBEMWgiELwZCFYMhC8H0tvsDGxka4j42NhXtVVVW4b21thftP+k+QX76vhcgMWQiGLARDFoIhC8FnLT7Z7e3tq216ejp87fPzc7gPDw+H+w87nfgQ78hCMGQhGLIQDFkIhiwEn7Uo0MvLS7h3dXW92o6Pj8PXZjKZcE96X4uWlpZ3Xh2az1qIy5CFYMhCMGQhGLIQPLUo0Pn5ebhns9l3f4/19fVwHx0dLeiafghPLcRlyEIwZCEYshAMWQj+h8gbLi8vw31wcPDd32N+fj7cR0ZGCromveYdWQiGLARDFoIhC8GQheCpxRuWlpbCPek0I9LX1xfuqVT42IAK4B1ZCIYsBEMWgiELwV/2/jo4OAj3hYWFL74SFcI7shAMWQiGLARDFoIhC8FTi79yuVy4Pzw8fOj7RG9MWF1dXdA16f28IwvBkIVgyEIwZCEYshA8tShQR0dHuO/s7Lza0ul0sS/nx/OOLARDFoIhC8GQhWDIQvCjF1Ru/OgFcRmyEAxZCIYsBEMWwlvPWvgueyoL3pGFYMhCMGQhGLIQDFkIhiyE/wGBTsFVR/FmfAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}